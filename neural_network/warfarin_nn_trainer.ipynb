{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9264c1",
   "metadata": {},
   "source": [
    "# Train a neural network to predict Therapeutic Dose of Warfarin that achieves a given INR\n",
    "---\n",
    "#### This notebook uses PyTorch to train a feed‑forward network\n",
    "  \n",
    "## How it works\n",
    "---\n",
    "* Read the CSV, treating Therapeutic Dose of Warfarin (mg/week) as the target.  \n",
    "\n",
    "* All other columns are used as features, including the patient's INR measured on their current dose. At inference time you can set the INR column to the value you *want* the patient to reach (e.g. 2.5) and obtain a recommended weekly dose.  \n",
    "\n",
    "* The numeric features are z‑score normalised with `sklearn.StandardScaler`.  \n",
    "\n",
    "* A simple fully‑connected network (3 hidden layers) is trained with mean‑squared‑error (MSE) loss.  \n",
    "\n",
    "* Validation metrics (RMSE & MAE) are printed every epoch.  \n",
    "\n",
    "* The best model (lowest validation RMSE) is saved to `best_model.pt`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105aa11",
   "metadata": {},
   "source": [
    "---\n",
    "# LIBRARY\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ffed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc166b05",
   "metadata": {},
   "source": [
    "---\n",
    "# CLASS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b5060",
   "metadata": {},
   "source": [
    "## Data wrapper around ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bedf98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarfarinDataset(Dataset):\n",
    "    \"\"\"Tensor-ready wrapper for (X, y) numpy arrays.\"\"\"\n",
    "\n",
    "    def __init__(self, X:np.ndarray, y:np.ndarray):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ddc06",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b52cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    # 512‑256‑128‑64 MLP with BatchNorm & LeakyReLU.\n",
    "    # Layer‑by‑layer breakdown\n",
    "    # -----------------------\n",
    "    # * Linear(in_dim → 512) – wide first layer captures pairwise feature interactions.\n",
    "    # * BatchNorm1d(512) – normalises activations, allowing higher LR andfaster convergence.\n",
    "    # * LeakyReLU() – avoids dead neurons with sparse inputs.\n",
    "    # * Dropout(0.3) – 30 % dropout for regularisation.\n",
    "    # * Linear(512 → 256) – compress learned representation.\n",
    "    # * BatchNorm1d(256) – keep scale/shift healthy after compression.\n",
    "    # * LeakyReLU() – another non‑linear mix.\n",
    "    # * Linear(256 → 128) – further compression.\n",
    "    # * BatchNorm1d(128) – stabilise.\n",
    "    # * LeakyReLU() – idem.\n",
    "    # * Linear(128 → 64) – penultimate dense layer.\n",
    "    # * LeakyReLU() – final activation.\n",
    "    # * Linear(64 → 1) – output single value log(dose).\n",
    "    #\n",
    "    # All `nn.Linear` layers are initialised with Kaiming normal weights and zero biases (see `_init_weights`) to match the LeakyReLU activations.\n",
    "\n",
    "    def __init__(self, in_dim:int):\n",
    "        super().__init__()\n",
    "        self.NN = nn.Sequential(\n",
    "            # First hidden layer – wide so the model can learn many feature interactions right away\n",
    "            nn.Linear(in_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3), # light regularization\n",
    "\n",
    "            # Second hidden layer – compress representation\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            # Third hidden layer – compress representation\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            # Fourth hidden layer – final non‑linear mixing\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            # Output layer – single continuous value (mg/week)\n",
    "            nn.Linear(64, 1), # output layer\n",
    "        )\n",
    "\n",
    "        # Apply good weight initialisation across all sub‑modules\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_weights(m):\n",
    "        \"\"\"Kaiming-uniform initialisation suited for LeakyReLU.\"\"\"\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='leaky_relu')\n",
    "            nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, X:torch.Tensor) -> torch.Tensor:\n",
    "        return self.NN(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5908ac",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8326bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"------------------ CONFIGURE ------------------\"\"\"\n",
    "MODEL_WEIGHTS: str = 'best_nn.pt'  # where to save checkpointed weights\n",
    "SCALER_FILE: str = 'scaler.pkl'    # where to save fitted StandardScaler\n",
    "RANDOM_STATE: int = 42\n",
    "TEST_SIZE: float = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62a10f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df:pd.DataFrame, target_col:str, epochs:int=100, batch_size:int=64, lr:float=1e-3):\n",
    "    \"\"\"------------------ 1) Load data ------------------\"\"\"\n",
    "    print('[*] Loading data...')\n",
    "    # Split dataset into features and target\n",
    "    X = df.drop(columns=[target_col]).values.astype(np.float32)\n",
    "    y = df[target_col].values.astype(np.float32)\n",
    "\n",
    "    # Train:Test -> 8:2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    \"\"\"\"------------------ 2) Fit scaler ------------------\"\"\"\n",
    "    print('[*] Scaling features...')\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = MinMaxScaler()\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "    # Persist scaler to re‑use at inference time\n",
    "    with open(SCALER_FILE, 'wb') as filo:\n",
    "        pickle.dump(scaler, filo)\n",
    "    \n",
    "\n",
    "    \"\"\"------------------ 3) Build datasets/loaders ------------------\"\"\"\n",
    "    print('[*] Wrapping train/test datasets...')\n",
    "    train_ds = WarfarinDataset(X_train_scaled, y_train)\n",
    "    test_ds = WarfarinDataset(X_test_scaled, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \"\"\"------------------ 4) Model/optimiser ------------------\"\"\"\n",
    "    print('[*] Initializing neural network...')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    print(f'\\tUsing {device}.')\n",
    "\n",
    "    model = FeedForwardNN(X_train.shape[1]).to(device)\n",
    "    print(f'\\tModel:\\n{model}\\n')\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=10, factor=0.5)\n",
    "    print(\n",
    "        f'\\tCirterion:\\n{criterion}\\n\\n'\n",
    "        f'\\tOptimizer:\\n{optimizer}\\n\\n'\n",
    "        f'\\tScheduler:\\n{scheduler}\\n\\n'\n",
    "    )\n",
    "\n",
    "    \"\"\"------------------ 5) Training loop ------------------\"\"\"\n",
    "    print(f'[*] Start training({epochs} epochs):')\n",
    "    best_test_rmse = float('inf')\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ---- train ----\n",
    "        model.train()\n",
    "        train_losses: List[float] = []\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_preds = model(x_batch)\n",
    "            loss = criterion(y_preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        # ---- test ----\n",
    "        model.eval()\n",
    "        test_losses: List[float] = []\n",
    "        test_preds, test_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                \n",
    "                y_preds = model(x_batch)\n",
    "                loss = criterion(y_preds, y_batch)\n",
    "                \n",
    "                test_losses.append(loss.item())\n",
    "                test_preds.append(y_preds.cpu().numpy())\n",
    "                test_targets.append(y_batch.cpu().numpy())\n",
    "        \n",
    "        test_preds_np = np.concatenate(test_preds).squeeze()\n",
    "        test_targets_np = np.concatenate(test_targets).squeeze()\n",
    "        test_rmse = rmse(test_targets_np, test_preds_np)\n",
    "        test_mae = mae(test_targets_np, test_preds_np)\n",
    "        \n",
    "        print(f'\\r\\tEpoch {epoch:03d}: Train MSE = {np.mean(train_losses):.4f} | Test RMSE = {test_rmse:.4f} | Test MAE = {test_mae:.4f}', end='')\n",
    "\n",
    "        # Plateau scheduler – auto LR decay if progress stalls\n",
    "        scheduler.step(test_rmse)\n",
    "\n",
    "        # Checkpoint if this epoch is best so far\n",
    "        if test_rmse < best_test_rmse:\n",
    "            best_test_rmse = test_rmse\n",
    "            torch.save(model.state_dict(), MODEL_WEIGHTS)\n",
    "        \n",
    "    \"\"\"------------------ 6) Done ------------------\"\"\"\n",
    "    print(\n",
    "        f'\\n[*] Training complete, best validation RMSE: {best_test_rmse:.4f}.\\n'\n",
    "        f'[*] Model saved to {MODEL_WEIGHTS}\\n'\n",
    "        f'[*] Scaler saved to {SCALER_FILE}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a836abc",
   "metadata": {},
   "source": [
    "---\n",
    "# TRAIN NEURAL NETWORK\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d76bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CSV: str = '../datasets/NN_Training_Data.csv'\n",
    "TARGET_COLUMN: str = 'Therapeutic Dose of Warfarin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6109af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "INR on Reported Therapeutic Dose of Warfarin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Therapeutic Dose of Warfarin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Weight (kg)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Height (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Valve Replacement",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gender_female",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gender_male",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age <50",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age 50-69",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age >=70",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Fluvastatin (Lescol)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Aspirin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Acetaminophen or Paracetamol (Tylenol)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Simvastatin (Zocor)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Cardiomyopathy/LV Dilation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Rifampin or Rifampicin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Diabetes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Anti-fungal Azoles",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d6750b92-bfce-44f5-a9f0-6804c96d1497",
       "rows": [
        [
         "0",
         "2.6",
         "49.0",
         "115.7",
         "193.04",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "2.15",
         "42.0",
         "144.2",
         "176.53",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "1.9",
         "53.0",
         "77.1",
         "162.56",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "2.4",
         "28.0",
         "90.7",
         "182.24",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "1.9",
         "42.0",
         "72.6",
         "167.64",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "5",
         "2.88",
         "49.0",
         "104.3",
         "177.8",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "6",
         "2.5",
         "71.0",
         "99.8",
         "187.96",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "7",
         "2.53",
         "18.0",
         "106.6",
         "160.02",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "8",
         "2.4",
         "17.0",
         "93.9",
         "177.8",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "9",
         "2.2",
         "49.0",
         "61.2",
         "167.64",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "10",
         "2.1",
         "42.0",
         "81.6",
         "172.72",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "11",
         "2.1",
         "14.0",
         "96.6",
         "165.1",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "12",
         "2.49",
         "70.0",
         "190.5",
         "200.66",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "13",
         "2.2",
         "28.0",
         "102.1",
         "182.88",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "14",
         "2.3",
         "10.0",
         "49.9",
         "157.48",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "15",
         "2.3",
         "91.0",
         "97.5",
         "177.8",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "16",
         "2.9",
         "30.0",
         "59.0",
         "175.26",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "17",
         "2.65",
         "49.0",
         "81.6",
         "187.96",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "18",
         "3.1",
         "28.0",
         "131.5",
         "165.1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "19",
         "3.0",
         "35.0",
         "95.3",
         "165.1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "20",
         "3.0",
         "63.0",
         "85.7",
         "162.56",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "21",
         "2.0",
         "35.0",
         "72.6",
         "165.1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "22",
         "2.8",
         "21.0",
         "77.1",
         "165.1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "23",
         "2.75",
         "21.0",
         "81.6",
         "185.42",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "24",
         "2.78",
         "28.0",
         "72.6",
         "167.64",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "25",
         "2.94",
         "77.0",
         "111.1",
         "187.96",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "26",
         "2.4",
         "42.0",
         "126.1",
         "180.34",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "27",
         "2.56",
         "18.0",
         "98.0",
         "172.72",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "28",
         "2.6",
         "56.0",
         "90.7",
         "180.34",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "29",
         "2.26",
         "88.0",
         "120.2",
         "180.34",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "30",
         "2.5",
         "12.0",
         "55.8",
         "153.67",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "31",
         "2.3",
         "21.0",
         "79.4",
         "166.37",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "32",
         "2.8",
         "44.0",
         "88.9",
         "165.1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "33",
         "2.9",
         "23.0",
         "88.5",
         "162.56",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "34",
         "2.3",
         "53.0",
         "74.8",
         "175.26",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "35",
         "2.1",
         "28.0",
         "72.6",
         "175.26",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "36",
         "3.0",
         "28.0",
         "83.9",
         "167.64",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "37",
         "2.5",
         "45.0",
         "81.6",
         "185.42",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "38",
         "2.8",
         "25.0",
         "115.7",
         "180.34",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "39",
         "2.65",
         "38.0",
         "102.1",
         "177.8",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "40",
         "2.2",
         "32.0",
         "113.4",
         "186.69",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "41",
         "2.9",
         "44.0",
         "75.7",
         "160.02",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "42",
         "3.0",
         "35.0",
         "77.6",
         "182.88",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "43",
         "2.0",
         "25.0",
         "68.0",
         "152.4",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "44",
         "2.5",
         "34.0",
         "63.5",
         "157.48",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "45",
         "1.8",
         "30.0",
         "74.8",
         "163.83",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "46",
         "2.4",
         "21.0",
         "74.8",
         "165.1",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "47",
         "2.1",
         "26.0",
         "56.7",
         "167.64",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "48",
         "2.8",
         "37.0",
         "72.6",
         "162.56",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "49",
         "1.8",
         "26.0",
         "40.4",
         "157.48",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 3989
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INR on Reported Therapeutic Dose of Warfarin</th>\n",
       "      <th>Therapeutic Dose of Warfarin</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Valve Replacement</th>\n",
       "      <th>Gender_female</th>\n",
       "      <th>Gender_male</th>\n",
       "      <th>Age &lt;50</th>\n",
       "      <th>Age 50-69</th>\n",
       "      <th>Age &gt;=70</th>\n",
       "      <th>Fluvastatin (Lescol)</th>\n",
       "      <th>Aspirin</th>\n",
       "      <th>Acetaminophen or Paracetamol (Tylenol)</th>\n",
       "      <th>Simvastatin (Zocor)</th>\n",
       "      <th>Cardiomyopathy/LV Dilation</th>\n",
       "      <th>Rifampin or Rifampicin</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Anti-fungal Azoles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.60</td>\n",
       "      <td>49.00</td>\n",
       "      <td>115.70</td>\n",
       "      <td>193.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.15</td>\n",
       "      <td>42.00</td>\n",
       "      <td>144.20</td>\n",
       "      <td>176.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.90</td>\n",
       "      <td>53.00</td>\n",
       "      <td>77.10</td>\n",
       "      <td>162.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.40</td>\n",
       "      <td>28.00</td>\n",
       "      <td>90.70</td>\n",
       "      <td>182.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.90</td>\n",
       "      <td>42.00</td>\n",
       "      <td>72.60</td>\n",
       "      <td>167.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>3.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>86.36</td>\n",
       "      <td>165.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>2.80</td>\n",
       "      <td>27.51</td>\n",
       "      <td>55.91</td>\n",
       "      <td>160.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>2.00</td>\n",
       "      <td>57.47</td>\n",
       "      <td>97.73</td>\n",
       "      <td>187.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>2.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>87.27</td>\n",
       "      <td>177.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>3.00</td>\n",
       "      <td>24.01</td>\n",
       "      <td>79.55</td>\n",
       "      <td>190.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3989 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      INR on Reported Therapeutic Dose of Warfarin  \\\n",
       "0                                             2.60   \n",
       "1                                             2.15   \n",
       "2                                             1.90   \n",
       "3                                             2.40   \n",
       "4                                             1.90   \n",
       "...                                            ...   \n",
       "3984                                          3.00   \n",
       "3985                                          2.80   \n",
       "3986                                          2.00   \n",
       "3987                                          2.00   \n",
       "3988                                          3.00   \n",
       "\n",
       "      Therapeutic Dose of Warfarin  Weight (kg)  Height (cm)  \\\n",
       "0                            49.00       115.70       193.04   \n",
       "1                            42.00       144.20       176.53   \n",
       "2                            53.00        77.10       162.56   \n",
       "3                            28.00        90.70       182.24   \n",
       "4                            42.00        72.60       167.64   \n",
       "...                            ...          ...          ...   \n",
       "3984                         35.00        86.36       165.10   \n",
       "3985                         27.51        55.91       160.02   \n",
       "3986                         57.47        97.73       187.96   \n",
       "3987                         70.00        87.27       177.80   \n",
       "3988                         24.01        79.55       190.50   \n",
       "\n",
       "      Valve Replacement  Gender_female  Gender_male  Age <50  Age 50-69  \\\n",
       "0                   0.0            0.0          1.0      0.0        1.0   \n",
       "1                   0.0            1.0          0.0      0.0        1.0   \n",
       "2                   0.0            1.0          0.0      1.0        0.0   \n",
       "3                   0.0            0.0          1.0      0.0        1.0   \n",
       "4                   0.0            0.0          1.0      0.0        1.0   \n",
       "...                 ...            ...          ...      ...        ...   \n",
       "3984                0.0            1.0          0.0      0.0        1.0   \n",
       "3985                0.0            1.0          0.0      0.0        0.0   \n",
       "3986                0.0            0.0          1.0      0.0        1.0   \n",
       "3987                0.0            0.0          1.0      0.0        1.0   \n",
       "3988                0.0            0.0          1.0      0.0        0.0   \n",
       "\n",
       "      Age >=70  Fluvastatin (Lescol)  Aspirin  \\\n",
       "0          0.0                   0.0      1.0   \n",
       "1          0.0                   0.0      0.0   \n",
       "2          0.0                   0.0      0.0   \n",
       "3          0.0                   0.0      0.0   \n",
       "4          0.0                   0.0      0.0   \n",
       "...        ...                   ...      ...   \n",
       "3984       0.0                   0.0      0.0   \n",
       "3985       1.0                   0.0      1.0   \n",
       "3986       0.0                   0.0      0.0   \n",
       "3987       0.0                   0.0      0.0   \n",
       "3988       1.0                   0.0      1.0   \n",
       "\n",
       "      Acetaminophen or Paracetamol (Tylenol)  Simvastatin (Zocor)  \\\n",
       "0                                        0.0                  0.0   \n",
       "1                                        0.0                  0.0   \n",
       "2                                        0.0                  0.0   \n",
       "3                                        0.0                  0.0   \n",
       "4                                        0.0                  0.0   \n",
       "...                                      ...                  ...   \n",
       "3984                                     0.0                  0.0   \n",
       "3985                                     0.0                  0.0   \n",
       "3986                                     0.0                  0.0   \n",
       "3987                                     0.0                  0.0   \n",
       "3988                                     0.0                  0.0   \n",
       "\n",
       "      Cardiomyopathy/LV Dilation  Rifampin or Rifampicin  Diabetes  \\\n",
       "0                            0.0                     0.0       0.0   \n",
       "1                            0.0                     0.0       0.0   \n",
       "2                            0.0                     0.0       0.0   \n",
       "3                            0.0                     0.0       0.0   \n",
       "4                            0.0                     0.0       0.0   \n",
       "...                          ...                     ...       ...   \n",
       "3984                         0.0                     0.0       1.0   \n",
       "3985                         0.0                     0.0       0.0   \n",
       "3986                         0.0                     0.0       0.0   \n",
       "3987                         0.0                     0.0       0.0   \n",
       "3988                         0.0                     0.0       0.0   \n",
       "\n",
       "      Anti-fungal Azoles  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "...                  ...  \n",
       "3984                 0.0  \n",
       "3985                 0.0  \n",
       "3986                 0.0  \n",
       "3987                 0.0  \n",
       "3988                 0.0  \n",
       "\n",
       "[3989 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_CSV)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e7e127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading data...\n",
      "[*] Scaling features...\n",
      "[*] Wrapping train/test datasets...\n",
      "[*] Initializing neural network...\n",
      "\tUsing mps.\n",
      "\tModel:\n",
      "FeedForwardNN(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=17, out_features=512, bias=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): LeakyReLU(negative_slope=0.01)\n",
      "    (7): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): LeakyReLU(negative_slope=0.01)\n",
      "    (10): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (11): LeakyReLU(negative_slope=0.01)\n",
      "    (12): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\tCirterion:\n",
      "MSELoss()\n",
      "\n",
      "\tOptimizer:\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "\n",
      "\tScheduler:\n",
      "<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x15f1cc1a0>\n",
      "\n",
      "\n",
      "[*] Start training(100 epochs):\n",
      "\tEpoch 100: Train MSE = 191.9712 | Test RMSE = 16.5290 | Test MAE = 11.1032\n",
      "[*] Training complete, best validation RMSE: 15.3628.\n",
      "[*] Model saved to best_nn.pt\n",
      "[*] Scaler saved to scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    df=df,\n",
    "    target_col=TARGET_COLUMN,\n",
    "    # epochs=500,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
