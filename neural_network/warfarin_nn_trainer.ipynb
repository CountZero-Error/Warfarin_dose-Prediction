{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9264c1",
   "metadata": {},
   "source": [
    "# Train a neural network to predict Therapeutic Dose of Warfarin that achieves a given INR\n",
    "---\n",
    "#### This notebook uses PyTorch to train a feed‑forward network\n",
    "  \n",
    "## How it works\n",
    "---\n",
    "* Read the CSV, treating Therapeutic Dose of Warfarin (mg/week) as the target.  \n",
    "\n",
    "* All other columns are used as features, including the patient's INR measured on their current dose. At inference time you can set the INR column to the value you *want* the patient to reach (e.g. 2.5) and obtain a recommended weekly dose.  \n",
    "\n",
    "* The numeric features are z‑score normalised with `sklearn.StandardScaler`.  \n",
    "\n",
    "* A simple fully‑connected network (3 hidden layers) is trained with mean‑squared‑error (MSE) loss.  \n",
    "\n",
    "* Validation metrics (RMSE & MAE) are printed every epoch.  \n",
    "\n",
    "* The best model (lowest validation RMSE) is saved to `best_model.pt`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105aa11",
   "metadata": {},
   "source": [
    "---\n",
    "# LIBRARY\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ffed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score as r2\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc166b05",
   "metadata": {},
   "source": [
    "---\n",
    "# CLASS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b5060",
   "metadata": {},
   "source": [
    "## Data wrapper around ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bedf98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarfarinDataset(Dataset):\n",
    "    \"\"\"Tensor-ready wrapper for (X, y) numpy arrays.\"\"\"\n",
    "\n",
    "    def __init__(self, X:np.ndarray, y:np.ndarray):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ddc06",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b52cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, in_dim:int):\n",
    "        super().__init__()\n",
    "        self.NN = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Linear(64, 1), # output layer – single continuous value (mg/week)\n",
    "            nn.ReLU()  # ensures dose ≥ 0\n",
    "        )\n",
    "\n",
    "        # Apply good weight initialisation across all sub‑modules\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_weights(m):\n",
    "        \"\"\"Kaiming-uniform initialisation suited for LeakyReLU.\"\"\"\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity='leaky_relu')\n",
    "            nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, X:torch.Tensor) -> torch.Tensor:\n",
    "        return self.NN(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5908ac",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8326bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"------------------ CONFIGURE ------------------\"\"\"\n",
    "MODEL_WEIGHTS: str = 'best_nn.pt'  # where to save checkpointed weights\n",
    "SCALER_FILE: str = 'scaler.pkl'    # where to save fitted StandardScaler\n",
    "RANDOM_STATE: int = 42\n",
    "TEST_SIZE: float = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62a10f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df:pd.DataFrame, target_col:str, epochs:int=100, batch_size:int=64, lr:float=1e-3):\n",
    "    \"\"\"------------------ 1) Load data ------------------\"\"\"\n",
    "    print('[*] Loading data...')\n",
    "    # Split dataset into features and target\n",
    "    X = df.drop(columns=[target_col]).values.astype(np.float32)\n",
    "    y = df[target_col].values.astype(np.float32)\n",
    "\n",
    "    # Train:Test -> 8:2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    \"\"\"\"------------------ 2) Fit scaler ------------------\"\"\"\n",
    "    print('[*] Scaling features...')\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = MinMaxScaler()\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "    # Persist scaler to re‑use at inference time\n",
    "    with open(SCALER_FILE, 'wb') as filo:\n",
    "        pickle.dump(scaler, filo)\n",
    "    \n",
    "\n",
    "    \"\"\"------------------ 3) Build datasets/loaders ------------------\"\"\"\n",
    "    print('[*] Wrapping train/test datasets...')\n",
    "    train_ds = WarfarinDataset(X_train_scaled, y_train)\n",
    "    test_ds = WarfarinDataset(X_test_scaled, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \"\"\"------------------ 4) Model/optimiser ------------------\"\"\"\n",
    "    print('[*] Initializing neural network...')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    print(f'\\tUsing {device}.')\n",
    "\n",
    "    model = FeedForwardNN(X_train.shape[1]).to(device)\n",
    "    print(f'\\tModel:\\n{model}\\n')\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=10, factor=0.5)\n",
    "    print(\n",
    "        f'\\tCirterion:\\n{criterion}\\n\\n'\n",
    "        f'\\tOptimizer:\\n{optimizer}\\n\\n'\n",
    "        f'\\tScheduler:\\n{scheduler}\\n\\n'\n",
    "    )\n",
    "\n",
    "    \"\"\"------------------ 5) Training loop ------------------\"\"\"\n",
    "    print(f'[*] Start training({epochs} epochs):')\n",
    "    best_test_rmse = float('inf')\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ---- train ----\n",
    "        model.train()\n",
    "        train_losses: List[float] = []\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_preds = model(x_batch)\n",
    "            loss = criterion(y_preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        # ---- test ----\n",
    "        model.eval()\n",
    "        test_losses: List[float] = []\n",
    "        test_preds, test_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                \n",
    "                y_preds = model(x_batch)\n",
    "                loss = criterion(y_preds, y_batch)\n",
    "                \n",
    "                test_losses.append(loss.item())\n",
    "                test_preds.append(y_preds.cpu().numpy())\n",
    "                test_targets.append(y_batch.cpu().numpy())\n",
    "        \n",
    "        test_preds_np = np.concatenate(test_preds).squeeze()\n",
    "        test_targets_np = np.concatenate(test_targets).squeeze()\n",
    "        test_rmse = rmse(test_targets_np, test_preds_np)\n",
    "        test_mae = mae(test_targets_np, test_preds_np)\n",
    "        test_r2 = r2(test_targets_np, test_preds_np)\n",
    "        \n",
    "        print(f'\\r\\tEpoch {epoch:03d}: Train MSE = {np.mean(train_losses):.4f} | Test RMSE = {test_rmse:.4f} | Test MAE = {test_mae:.4f} | Test R² = {test_r2:.4f}', end='')\n",
    "\n",
    "        # Plateau scheduler – auto LR decay if progress stalls\n",
    "        scheduler.step(test_rmse)\n",
    "\n",
    "        # Checkpoint if this epoch is best so far\n",
    "        if test_rmse < best_test_rmse:\n",
    "            best_test_rmse = test_rmse\n",
    "            torch.save(model.state_dict(), MODEL_WEIGHTS)\n",
    "        \n",
    "    \"\"\"------------------ 6) Done ------------------\"\"\"\n",
    "    print(\n",
    "        f'\\n[*] Training complete, best validation RMSE: {best_test_rmse:.4f}.\\n'\n",
    "        f'[*] Model saved to {MODEL_WEIGHTS}\\n'\n",
    "        f'[*] Scaler saved to {SCALER_FILE}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a836abc",
   "metadata": {},
   "source": [
    "---\n",
    "# TRAIN NEURAL NETWORK\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d76bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CSV: str = '../datasets/NN_Training_Data.csv'\n",
    "TARGET_COLUMN: str = 'Therapeutic Dose of Warfarin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6109af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "INR on Reported Therapeutic Dose of Warfarin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Therapeutic Dose of Warfarin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Weight (kg)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Height (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gender_male",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VKORC1 -1639 consensus_A/G",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "VKORC1 -1639 consensus_G/G",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CYP2C9 consensus_*1/*2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CYP2C9 consensus_*2/*3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CYP2C9 consensus_*1/*3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Amiodarone (Cordarone)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CYP2C9 consensus_*2/*2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CYP2C9 consensus_*1/*14",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CYP2C9 consensus_*3/*3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Anti-fungal Azoles",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Current Smoker",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Diabetes",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1f8cacfd-7925-4ff5-a17a-cbc70617a2f4",
       "rows": [
        [
         "0",
         "2.13",
         "35.0",
         "75.5",
         "173.48199999981264",
         "1",
         "84.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "2.33",
         "17.5",
         "70.0",
         "166.11599999982062",
         "1",
         "84.5",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "1.9",
         "20.0",
         "88.6",
         "176.0219999998099",
         "1",
         "74.5",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "3",
         "2.83",
         "30.0",
         "92.0",
         "176.0219999998099",
         "1",
         "74.5",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "2.33",
         "42.0",
         "114.0",
         "178.56199999980714",
         "1",
         "54.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "5",
         "2.1",
         "36.8",
         "73.6",
         "178.56199999980714",
         "1",
         "64.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "6",
         "2.27",
         "87.5",
         "109.0",
         "181.1019999998044",
         "1",
         "44.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "7",
         "3.0",
         "42.5",
         "105.0",
         "181.1019999998044",
         "1",
         "84.5",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "8",
         "2.37",
         "12.5",
         "75.0",
         "171.19599999981514",
         "1",
         "74.5",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "9",
         "2.47",
         "17.5",
         "61.4",
         "155.95599999983156",
         "0",
         "64.5",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "10",
         "2.07",
         "52.5",
         "72.7",
         "155.95599999983156",
         "0",
         "84.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "11",
         "2.95",
         "70.0",
         "136.8",
         "166.11599999982062",
         "0",
         "64.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "12",
         "2.33",
         "42.5",
         "109.0",
         "181.1019999998044",
         "1",
         "64.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "13",
         "2.33",
         "35.0",
         "101.0",
         "186.18199999979893",
         "1",
         "74.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "14",
         "2.87",
         "20.0",
         "52.3",
         "155.95599999983156",
         "0",
         "84.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "15",
         "2.67",
         "52.5",
         "90.9",
         "161.0359999998261",
         "0",
         "64.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "16",
         "2.83",
         "28.0",
         "62.3",
         "166.11599999982062",
         "0",
         "74.5",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "17",
         "2.3",
         "52.5",
         "90.9",
         "183.64199999980167",
         "1",
         "64.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "18",
         "2.5",
         "22.0",
         "90.9",
         "181.1019999998044",
         "1",
         "64.5",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "19",
         "2.43",
         "30.0",
         "59.1",
         "155.95599999983156",
         "0",
         "84.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "20",
         "2.17",
         "19.25",
         "70.9",
         "168.65599999981788",
         "1",
         "74.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "21",
         "2.2",
         "20.0",
         "87.3",
         "176.0219999998099",
         "1",
         "74.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "22",
         "2.63",
         "45.0",
         "95.0",
         "176.0219999998099",
         "1",
         "54.5",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "23",
         "2.43",
         "75.0",
         "94.5",
         "176.0219999998099",
         "1",
         "54.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "24",
         "2.3",
         "10.0",
         "123.0",
         "181.1019999998044",
         "1",
         "84.5",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "25",
         "2.27",
         "28.0",
         "175.0",
         "167.64",
         "0",
         "54.5",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "26",
         "2.55",
         "48.0",
         "159.0",
         "170.18",
         "0",
         "34.5",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "27",
         "2.37",
         "28.0",
         "129.0",
         "193.04",
         "1",
         "54.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1.0",
         "1",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "28",
         "2.77",
         "42.5",
         "88.2",
         "181.1019999998044",
         "1",
         "54.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "1.0",
         "1.0"
        ],
        [
         "29",
         "2.83",
         "57.5",
         "85.9",
         "163.57599999982335",
         "1",
         "64.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "30",
         "2.47",
         "42.5",
         "88.6",
         "181.1019999998044",
         "1",
         "84.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "31",
         "2.67",
         "39.0",
         "73.5",
         "171.19599999981514",
         "1",
         "64.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "32",
         "2.67",
         "37.5",
         "73.4",
         "171.19599999981514",
         "1",
         "74.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "33",
         "2.27",
         "27.5",
         "177.3",
         "183.88",
         "1",
         "64.5",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "34",
         "2.87",
         "40.0",
         "88.6",
         "178.56199999980714",
         "1",
         "54.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "35",
         "2.63",
         "43.3",
         "86.4",
         "178.56199999980714",
         "1",
         "84.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "36",
         "3.6",
         "35.6",
         "55.5",
         "163.57599999982335",
         "0",
         "44.5",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "37",
         "2.33",
         "57.5",
         "100.9",
         "173.73599999981238",
         "1",
         "64.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "38",
         "2.6",
         "22.5",
         "72.7",
         "176.0219999998099",
         "1",
         "64.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1.0",
         "0",
         "0",
         "0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "39",
         "2.3",
         "55.0",
         "101.8",
         "178.56199999980714",
         "1",
         "64.5",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "40",
         "2.4",
         "32.5",
         "115.0",
         "173.73599999981238",
         "1",
         "64.5",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "41",
         "2.53",
         "42.5",
         "108.0",
         "183.64199999980167",
         "1",
         "64.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "42",
         "2.63",
         "40.0",
         "103.0",
         "176.0219999998099",
         "1",
         "74.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "43",
         "2.33",
         "25.0",
         "93.0",
         "171.19599999981514",
         "1",
         "74.5",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "44",
         "2.5",
         "17.5",
         "78.0",
         "168.65599999981788",
         "1",
         "84.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "45",
         "2.4",
         "28.0",
         "89.0",
         "171.19599999981514",
         "1",
         "74.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "46",
         "2.97",
         "30.0",
         "91.0",
         "178.56199999980714",
         "1",
         "74.5",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "47",
         "2.5",
         "15.0",
         "68.0",
         "160.02",
         "1",
         "74.5",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "48",
         "2.33",
         "25.0",
         "91.0",
         "168.65599999981788",
         "1",
         "84.5",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "49",
         "3.27",
         "28.0",
         "90.0",
         "183.64199999980167",
         "1",
         "54.5",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 1487
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INR on Reported Therapeutic Dose of Warfarin</th>\n",
       "      <th>Therapeutic Dose of Warfarin</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Gender_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>VKORC1 -1639 consensus_A/G</th>\n",
       "      <th>VKORC1 -1639 consensus_G/G</th>\n",
       "      <th>CYP2C9 consensus_*1/*2</th>\n",
       "      <th>CYP2C9 consensus_*2/*3</th>\n",
       "      <th>CYP2C9 consensus_*1/*3</th>\n",
       "      <th>Amiodarone (Cordarone)</th>\n",
       "      <th>CYP2C9 consensus_*2/*2</th>\n",
       "      <th>CYP2C9 consensus_*1/*14</th>\n",
       "      <th>CYP2C9 consensus_*3/*3</th>\n",
       "      <th>Anti-fungal Azoles</th>\n",
       "      <th>Current Smoker</th>\n",
       "      <th>Diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.13</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>75.50</td>\n",
       "      <td>173.482</td>\n",
       "      <td>1</td>\n",
       "      <td>84.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.33</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>70.00</td>\n",
       "      <td>166.116</td>\n",
       "      <td>1</td>\n",
       "      <td>84.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.90</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>88.60</td>\n",
       "      <td>176.022</td>\n",
       "      <td>1</td>\n",
       "      <td>74.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.83</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>92.00</td>\n",
       "      <td>176.022</td>\n",
       "      <td>1</td>\n",
       "      <td>74.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.33</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>114.00</td>\n",
       "      <td>178.562</td>\n",
       "      <td>1</td>\n",
       "      <td>54.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>2.30</td>\n",
       "      <td>39.974286</td>\n",
       "      <td>77.27</td>\n",
       "      <td>180.340</td>\n",
       "      <td>1</td>\n",
       "      <td>64.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>2.30</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>84.55</td>\n",
       "      <td>180.340</td>\n",
       "      <td>1</td>\n",
       "      <td>74.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>2.90</td>\n",
       "      <td>49.980000</td>\n",
       "      <td>90.91</td>\n",
       "      <td>185.420</td>\n",
       "      <td>1</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>2.50</td>\n",
       "      <td>42.490000</td>\n",
       "      <td>86.36</td>\n",
       "      <td>157.480</td>\n",
       "      <td>0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>2.90</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>125.00</td>\n",
       "      <td>187.960</td>\n",
       "      <td>1</td>\n",
       "      <td>54.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1487 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      INR on Reported Therapeutic Dose of Warfarin  \\\n",
       "0                                             2.13   \n",
       "1                                             2.33   \n",
       "2                                             1.90   \n",
       "3                                             2.83   \n",
       "4                                             2.33   \n",
       "...                                            ...   \n",
       "1482                                          2.30   \n",
       "1483                                          2.30   \n",
       "1484                                          2.90   \n",
       "1485                                          2.50   \n",
       "1486                                          2.90   \n",
       "\n",
       "      Therapeutic Dose of Warfarin  Weight (kg)  Height (cm)  Gender_male  \\\n",
       "0                        35.000000        75.50      173.482            1   \n",
       "1                        17.500000        70.00      166.116            1   \n",
       "2                        20.000000        88.60      176.022            1   \n",
       "3                        30.000000        92.00      176.022            1   \n",
       "4                        42.000000       114.00      178.562            1   \n",
       "...                            ...          ...          ...          ...   \n",
       "1482                     39.974286        77.27      180.340            1   \n",
       "1483                     28.000000        84.55      180.340            1   \n",
       "1484                     49.980000        90.91      185.420            1   \n",
       "1485                     42.490000        86.36      157.480            0   \n",
       "1486                     52.500000       125.00      187.960            1   \n",
       "\n",
       "       Age  VKORC1 -1639 consensus_A/G  VKORC1 -1639 consensus_G/G  \\\n",
       "0     84.5                           1                           0   \n",
       "1     84.5                           1                           0   \n",
       "2     74.5                           1                           0   \n",
       "3     74.5                           1                           0   \n",
       "4     54.5                           1                           0   \n",
       "...    ...                         ...                         ...   \n",
       "1482  64.5                           1                           0   \n",
       "1483  74.5                           1                           0   \n",
       "1484  54.5                           0                           1   \n",
       "1485  74.5                           0                           1   \n",
       "1486  54.5                           1                           0   \n",
       "\n",
       "      CYP2C9 consensus_*1/*2  CYP2C9 consensus_*2/*3  CYP2C9 consensus_*1/*3  \\\n",
       "0                          0                       0                       0   \n",
       "1                          0                       0                       1   \n",
       "2                          1                       0                       0   \n",
       "3                          1                       0                       0   \n",
       "4                          0                       0                       0   \n",
       "...                      ...                     ...                     ...   \n",
       "1482                       0                       0                       0   \n",
       "1483                       1                       0                       0   \n",
       "1484                       1                       0                       0   \n",
       "1485                       0                       0                       0   \n",
       "1486                       0                       0                       0   \n",
       "\n",
       "      Amiodarone (Cordarone)  CYP2C9 consensus_*2/*2  CYP2C9 consensus_*1/*14  \\\n",
       "0                        0.0                       0                        0   \n",
       "1                        0.0                       0                        0   \n",
       "2                        0.0                       0                        0   \n",
       "3                        0.0                       0                        0   \n",
       "4                        0.0                       0                        0   \n",
       "...                      ...                     ...                      ...   \n",
       "1482                     0.0                       0                        0   \n",
       "1483                     0.0                       0                        0   \n",
       "1484                     0.0                       0                        0   \n",
       "1485                     0.0                       0                        0   \n",
       "1486                     1.0                       0                        0   \n",
       "\n",
       "      CYP2C9 consensus_*3/*3  Anti-fungal Azoles  Current Smoker  Diabetes  \n",
       "0                          0                 0.0             0.0       0.0  \n",
       "1                          0                 0.0             0.0       0.0  \n",
       "2                          0                 0.0             0.0       1.0  \n",
       "3                          0                 0.0             0.0       0.0  \n",
       "4                          0                 0.0             0.0       0.0  \n",
       "...                      ...                 ...             ...       ...  \n",
       "1482                       0                 0.0             1.0       0.0  \n",
       "1483                       0                 0.0             0.0       1.0  \n",
       "1484                       0                 0.0             1.0       0.0  \n",
       "1485                       0                 0.0             0.0       0.0  \n",
       "1486                       0                 0.0             0.0       1.0  \n",
       "\n",
       "[1487 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_CSV)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e7e127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading data...\n",
      "[*] Scaling features...\n",
      "[*] Wrapping train/test datasets...\n",
      "[*] Initializing neural network...\n",
      "\tUsing mps.\n",
      "\tModel:\n",
      "FeedForwardNN(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=17, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (6): ReLU()\n",
      "  )\n",
      ")\n",
      "\n",
      "\tCirterion:\n",
      "MSELoss()\n",
      "\n",
      "\tOptimizer:\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "\n",
      "\tScheduler:\n",
      "<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x13a7d01a0>\n",
      "\n",
      "\n",
      "[*] Start training(100 epochs):\n",
      "\tEpoch 100: Train MSE = 166.8431 | Test RMSE = 20.3996 | Test MAE = 10.2971 | Test R² = 0.168438\n",
      "[*] Training complete, best validation RMSE: 20.3665.\n",
      "[*] Model saved to best_nn.pt\n",
      "[*] Scaler saved to scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    df=df,\n",
    "    target_col=TARGET_COLUMN,\n",
    "    # epochs=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e8edaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
